<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
    
    </script>

    <script async defer src="https://buttons.github.io/buttons.js">
    </script>

	
  <title>Tian Liu</title>
  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
  <meta name="author" content="Tian Liu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="stylesheet" type="text/css" href="css/style.css">
  <link rel="icon" type="image/png" href="images/tian_liu.png">

	
</head>

<body>
  <table style="width:100%;max-width:920px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
	      
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <td style="padding:0%;width:75%;vertical-align:middle">
		  <!-- <br> -->
		  <!-- <br> -->
	      <p style="text-align:center"> <name> Tian Liu </name> </p>

		<p></p>
		
		
        <p> Hi, I am a 2nd year PhD student in the <a href="https://aimerykong.github.io/group.html" target="_blank">Computer Vision Lab</a> of <a href="https://engineering.tamu.edu/cse/index.html">CSE department</a> at
			<a href="https://www.tamu.edu/index.html" target="_blank">Texas A&M University</a> (TAMU), 
			working with <a href="https://aimerykong.github.io/" target="_blank">Prof. Shu Kong</a>. 
			<!-- My current research focuses on adapting pretrained Vision-Language Models to downstream tasks in zero-shot or few-shot setup. -->
			Previously, I obtained a M.S. degree from <a href="https://engineering.tamu.edu/cse/index.html" target="_blank">Computer Science</a>, TAMU in 2023, 
			and a M.S. degree from <a href="https://engineering.tamu.edu/petroleum/index.html" target="_blank">Petroleum Engineering</a>, TAMU in 2019. 
			I worked as a field engineer in <a href="https://www.slb.com/" target="_blank">Schlumberger</a> (2019-2020) 
			and interned as a System Software Engineer (2021, 2022) at <a href="https://www.hpe.com/us/en/home.html" target="_blank">HPE</a>.
		</p>
			 

		<p>
              <p style="text-align:center">
                <a href="mailto:tianliu1327@gmail.com">Email</a> &nbsp/&nbsp
				<a href="https://scholar.google.com/citations?hl=en&user=qgmIiSsAAAAJ&view_op=list_works&sortby=pubdate" target="_blank"> Google Scholar </a> &nbsp/&nbsp
				<a href=""> CV </a> &nbsp/&nbsp
				<a href="https://www.linkedin.com/in/tian1327/" target="_blank"> LinkedIn </a> &nbsp/&nbsp
				<a href="https://github.com/tian1327" target="_blank"> Github </a>
              </p>
	  
            </td>
            <td style="padding:2.5%;width:20%;max-width:23%">
              <a href="images/tian_liu.png"><img style="width:120%;max-width:100%" alt="profile photo" src="images/tian_liu.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>



	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <p><heading>News</heading> </p>
		<p> 

	 <ul class="b"> 
	<li> June 2024: Coordinated the <a href="https://vplow.github.io/vplow_4th.html" target="_blank">4th Open World Vision Workshop</a> at CVPR'24. </li>
	<li> June 2024: I will present our paper in CVPR'24, Seattle. </li>
	<li> June 2024: Our paper "The Neglected Tails in Vision-Language Models" was accepted to <b>ICML 2024 DMLR Oral</b>. </li>
	<li> Mar 2024: I was awarded TAMU CSE department travel grant. </li>
	<li> Mar 2024: I received TAMU CSE <b>Graduate Teaching Assistant Excellence Award</b> (1 each year). </li>
	<li> Mar 2024: I passed Ph.D. qualify exam with 99% percentile. </li>
	<li> Feb 2024: 1 paper accepted to <a href="https://cvpr.thecvf.com/" target="_blank">CVPR'24</a>. </li>



	</ul>	

		
        </td>
        </tbody></table>
	
	<p> 
	<p> 
		
		
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <p><heading>Research</heading> </p>
		<p> 
	My research interest includes <b>computer vision</b>, <b>cyber-physical systems</b>, and <b>machine learning for healthcare</b>.
	My current research focuses on analyzing the limitations of pretrained foundation models (e.g. Vision-Language Models)  
	and developing better algorithms to adapt foundation models to downstream tasks in zero-shot and few-shot setup.
	 <!-- <ul class="b"> 
	<li> <b>Machine Learning Systems for IoT</b>: addresses real-world challenges for advancing ML in mobile/IoT systems, such as distributed and imperfect IoT data, scalability, limited resources, and real-world system dynamics.  </li>
	<li><b>Cyber-physical Systems</b>: design and deploy real-world IoT systems for precision residential irrigation system and , e.g., developing multi-modal federated learning systems for <a href="https://cuhk-alzheimers-ai.github.io/">monitoring digital biomarkers of Alzheimerâ€™s Disease</a>. </li>
	<li><b>Machine Learning for Healthcare</b>: develop safe reinforcement learning algorithms and models for . </li>
		 
	</ul>	
	<b>Keywords of my recent research topics</b>: Vision-Language Models, zero/few-shot recognition, video understanding
	</td> -->
    </tbody></table>

		
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		
	<!-- <p><heading>Major Publications</heading></p> -->

	<ul class="b">

	  <tr">
	    <td style="padding:0px;width:40%;vertical-align:middle">
	    <div class="one" style="text-align:center;">
		<img src='images/swat_teaser.png' width="350" >
	    </div>
	    </td>
		<td style="padding:10px;width:75%;vertical-align:middle">
		<p> 
			<a href="https://arxiv.org/abs/2406.11148" target="_blank"> Few-Shot Recognition via Stage-Wise Augmented Finetuning</a>
		</p>
		<u><b>Tian Liu</b></u>, Huixin Zhang, Shubham Parashar, Shu Kong<br>		
		<!-- <em>CVPR</em>, 2024		 -->
		<p> 
			<a href="https://arxiv.org/abs/2406.11148" target="_blank"> arxiv</a> /
			<a href="https://tian1327.github.io/SWAT/" target="_blank"> project</a> /
			<a href="https://github.com/tian1327/SWAT" target="_blank"> code</a>
		</p> 
		<p>We explore retrieval-augmented learning for few-shot recognition, 
			and propose Stage-Wise Augmented fineTuning (SWAT) method to mitigate the imbalanced distribution and domain gap issues, 
			outperforming previous SOTA methods by >10% accuracy. </p>
		</td>			
		</tr>
			

		<tr">
	    <td style="padding:0px;width:40%;vertical-align:middle">
	    <div class="one" style="text-align:center;">
		<img src='images/real_teaser.jpg' width="350" >
	    </div>
	    </td>
		<td style="padding:10px;width:75%;vertical-align:middle">
		<p> <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Parashar_The_Neglected_Tails_in_Vision-Language_Models_CVPR_2024_paper.pdf" target="_blank"> 
			The Neglected Tails in Vision-Language Models</a>
		</p>
		Shubham Parashar*, Zhiqiu Lin*, <u><b>Tian Liu*</b></u> (*co-first authors), Xiangjue Dong,
		Yanan Li, Deva Ramanan, James Caverlee, Shu Kong<br>
		<p> 
			[<b>CVPR 2024, <a href="https://dmlr.ai/" target="_blank">ICML 2024 DMLR</a> <font color="red">Oral</font></b>]	 &nbsp;
			<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Parashar_The_Neglected_Tails_in_Vision-Language_Models_CVPR_2024_paper.pdf" target="_blank"> paper</a> /
			<a href="https://openreview.net/pdf?id=ApWIco3gwD" target="_blank"> DMLR</a> /
			<a href="https://arxiv.org/abs/2401.12425" target="_blank"> arxiv</a> /			
			<a href="https://shubhamprshr27.github.io/neglected-tails-of-vlms/" target="_blank"> project</a> /
			<a href="https://github.com/shubhamprshr27/NeglectedTailsVLM" target="_blank"> code</a>
		</p> 
		<p>We expose the long-tailed concept distributions in VLMs' pretraining data 
			and reveal failues of SOTA multimodal systems (e.g. GPT-4V, DALL-E 3). 
			We propose retrieval-augmented learning, achieving SOTA zero-shot recognition performance. </p>
		</p>
		</td>			
		</tr>





		<tr">
	    <td style="padding:0px;width:40%;vertical-align:middle">
	    <div class="one" style="text-align:center;">
		<img src='images/emsassist_teaser.png' width="350"height="150">
	    </div>
	    </td>
		<td style="padding:10px;width:75%;vertical-align:middle">
		<p> <a href="https://dl.acm.org/doi/pdf/10.1145/3581791.3596853" target="_blank"> 
			EMSAssist: An End-to-End Mobile Voice Assistant at the Edge for
			Emergency Medical Services</a>
		</p>
		Liuyi Jin, <u><b>Tian Liu</b></u>, Amran Haroon, Radu Stoleru, Michael Middleton, Ziwei Zhu, Theodora Chaspari<br>
		<p> 
			[<b>MobiSys 2023</b>] &nbsp;
			<a href="https://dl.acm.org/doi/pdf/10.1145/3581791.3596853" target="_blank"> paper</a> /
			<a href="https://dl.acm.org/doi/pdf/10.1145/3581791.3597290" target="_blank">demo</a> /
			<a href="https://github.com/LENSS/EMSAssist" target="_blank"> code</a>
		</p> 
		<p>We build the first end-to-end mobile voice assistant system to assist Emergency Medical Technicians in selecting proper protocols for critical medical intervention. </p>
		</p>
		</td>			
		</tr>



		<tr">
	    <td style="padding:0px;width:40%;vertical-align:middle">
	    <div class="one" style="text-align:center;">
		<img src='images/cops_teaser.png' width="350"height="150">
	    </div>
	    </td>
		<td style="padding:10px;width:75%;vertical-align:middle">
		<p> <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4583667" target="_blank"> 
			Safe Reinforcement Learning with Contextual Information: Theory and Applications</a>
		</p>
		Junyu Cao, Esmaeil Keyvanshokooh, <u><b>Tian Liu</b></u> <br>
		<p> 
			<!-- [<b>MobiSys 2023</b>] &nbsp; -->
			<a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4583667" target="_blank"> ssrn</a> /
			<a href="" target="_blank"> code</a>
		</p> 
		<p>We develop a safe reinforcement learning algorithm for personalized medical prescription considering patient's contextual information
			(e.g. age, gender, race etc.),
			achieveing sub-linear regret with zero safety violation.
		</p>
		</p>
		</td>			
		</tr>


		<tr">
	    <td style="padding:0px;width:40%;vertical-align:middle">
	    <div class="one" style="text-align:center;">
		<img src='images/vae_frac.png' width="350"height="150">
	    </div>
	    </td>
		<td style="padding:10px;width:75%;vertical-align:middle">
		<p> <a href="https://www.sciencedirect.com/science/article/pii/S0266352X2400082X" target="_blank"> 
			A Machine Learning-based Hybrid Model for Fracture Parameterization and
			Distribution Prediction in Unconventional Reservoirs</a>
		</p>
		<u><b>Tian Liu</b></u>, Ruxin Zhang <br>
		<p> 
			[<b>Computers and Geotechnics 2024</b>] &nbsp;
			<a href="https://www.sciencedirect.com/science/article/pii/S0266352X2400082X" target="_blank"> paper</a> 
			<!-- <a href="" target="_blank"> code</a> -->
		</p> 
		<p>We develop Variational Autoencoder (VAE) model for fracture parameterization 
			and distribution prediction using reservoir production data.
		</p>
		</p>
		</td>			
		</tr>




		<tr">
	    <td style="padding:0px;width:40%;vertical-align:middle">
	    <div class="one" style="text-align:center;">
		<img src='images/onset_time.png' width="350"height="150">
	    </div>
	    </td>
		<td style="padding:10px;width:75%;vertical-align:middle">
		<p> <a href="https://www.sciencedirect.com/science/article/pii/S0920410520300851" target="_blank"> 
			Integration of Time-lapse Seismic Data using the Onset Time Approach: the Impact of Seismic Survey Frequency</a>
		</p>
		<u><b>Tian Liu</b></u>, Hongquan Chen, Gill Hetz, Akhil Datta-Gupta <br>
		<p> 
			[<b>Journal of Petroleum Science and Engineering 2020</b>] &nbsp;
			<a href="https://www.sciencedirect.com/science/article/pii/S0920410520300851" target="_blank"> paper</a> 
			<!-- <a href=""> code</a> -->
		</p> 
		<p>We develop onset-time approach for efficient 
			and robust integration of 4D seismic data for reservoir model calibration, achieveing 2x error reduction and 6x speedup 
			compared to traditional amplitude-matching methods. 
		</p>
		</p>
		</td>			
		</tr>



		
	<!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
               <p><heading>Other Publications</heading> </p>
		<p> 
	     <ul class="b">
		     
		<li> <a href="https://www.sciencedirect.com/science/article/pii/S0266352X2400082X" target="_blank"> A Machine Learning-based Hybrid Model for Fracture Parameterization and
			Distribution Prediction in Unconventional Reservoirs </a> 
		</li>
		<u><b>Tian Liu</b></u>, Ruxin Zhang<br>
		<i>Computers and Geotechnics, 2024.</i><br></p>
		 </td>
        </tbody></table>
		
	<p> <p> -->



	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
               <!-- <p><heading>Teaching Experience</heading> </p> -->
               <p><heading>Teaching Assistance</heading> </p>

		<p> 
	     <ul class="b">
	
		<!-- <p> <b> Mentering Experience </b> </p> -->
		<!-- <li>Huixin Zhang, Ph.D. student at TAMU </li> -->
		<!-- <li>Hasnat Md. Abdullah, Ph.D. student at TAMU </li> -->
		<!-- <li>Anwesha Basu, M.S. student at TAMU </li> -->
		<!-- <li>Yang Yang, undergraduate student at Georgia Tech </li> -->


		     
	<p> 
		
	  <!-- <p> <b> Teaching Assistant</b> </p> -->
	     <li> CSCE606: Software Engineering, 2023 Fall</li> </li>
	     <li> CSCE313: Introduction to Computer Systems, 2023 Summer</li> </li>
	     <li> CSCE110: Programming I, 2023 Summer</li> </li>
	     </ul>

            </td>
        </tbody></table>

	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
               <p><heading>Professional Services</heading> </p>
		<!-- <p>  -->
	     <ul class="b">
		  <!-- <p> <b> Organizing Committee Member </b> </p> -->
		  <!-- <p> <b> Organizing Conference </b> </p> -->

		      <li> Coordinator of <a href="https://vplow.github.io/vplow_4th.html" target="_blank">4th Open World Vision Workshop</a> at CVPR'24.</a> </li>
		     <!-- </p> -->
		    
		
              <!-- <p> <b> Invited Reviewer</b> </p> -->
	      <li> Reviewer for Pattern Recognition</li>
	      <li> Reviewer for Applied Thermal Engineering, Geoenergy Science and Enginerring, SPE Journal</li>
  
		</p>

	     </ul>

            </td>
        </tbody></table>


		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
               <p><heading>Selected Awards</heading> </p>
		<p> 
	     <ul class="b"> 
			<li> TAMU CSE Department Travel Grant, <em>2024</em> </li>
			<li> TAMU CSE Department <b>Graduate Teaching Assistant Excellence Award</b> (1 each year), <em>2024</em> </li>
			<li> 1st place of SPE Student Paper Contest in TAMU, 1st place of Gulf Coast Region, 3rd place of worldwide Championship, <em>2018</em> </li>			
			<li> 2nd place of SPE Petrobowl Knowledge Contest in North American Region, <em>2017</em> </li>
			<li> 1st place of SPE Petrobowl Knowledge Contest in Asia-Pacific Region, <em>2015</em> </li>
			<li> Dean's Award (4 out of 296), China University of Petroleum Beijing, <em>2014</em> </li>
	      <li> National Scholarship (highest honor in China), Ministry of Education of China, <em>2012</em> </li>
	     </ul>

            </td>
        </tbody></table>

		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
			<p><heading>Miscellaneous</heading> </p>
	  <ul class="b">

		<li> I have two big (20 lbs :) orange Maine Coon brothers, named <a href="images/thor_loki.png" target="_blank">Thor and Loki</a> .</a> </li>
	 </p>
	  </ul>
		 </td>
	 </tbody></table>

	<p>
	<p>
	           <!-- CopyRight -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
 		<p style="text-align:right;">Template from <a href="https://xmouyang.github.io/">Xiaomin Ouyang</a></p>
                </tbody>
            </table>
		
      </td>
    </tr>
  </table>
</body>

<!-- <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=Bh_ukE5Vq8_S7PMZdvQG_-pm22VHQx3fzCtcZwgh7lI"></script> -->

</html>
