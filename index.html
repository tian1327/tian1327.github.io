<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
    
    </script>

    <script async defer src="https://buttons.github.io/buttons.js">
    </script>

	
  <title>Tian Liu</title>
  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
  <meta name="author" content="Tian Liu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="stylesheet" type="text/css" href="css/style.css">
  <link rel="icon" type="image/png" href="images/tian_liu.png">

	
</head>

<body>
  <table style="width:100%;max-width:920px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
	      
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <td style="padding:0%;width:75%;vertical-align:middle">
		  <!-- <br> -->
		  <!-- <br> -->
	      <p style="text-align:center"> <name> Tian Liu </name> </p>

		<p></p>
		
		
        <p> Hi there! I am a 2nd year PhD student in the <a href="https://aimerykong.github.io/group.html" target="_blank">Computer Vision Lab</a> 
			at <a href="https://engineering.tamu.edu/cse/index.html">CSE department</a> of
			<a href="https://www.tamu.edu/index.html" target="_blank">Texas A&M University</a> (TAMU), 
			working with <a href="https://aimerykong.github.io/" target="_blank">Prof. Shu Kong</a> 
			and <a href="https://people.engr.tamu.edu/caverlee/index.html" target="_blank">Prof. James Caverlee</a>. 
			Previously, I obtained my M.S. degree of <a href="https://engineering.tamu.edu/cse/index.html" target="_blank">Computer Science</a>, at TAMU in 2023, 
			and a M.S. degree of <a href="https://engineering.tamu.edu/petroleum/index.html" target="_blank">Petroleum Engineering</a>, at TAMU in 2019. 
			I worked as a field engineer for <a href="https://www.slb.com/" target="_blank">Schlumberger</a> (2019-2020) 
			and interned as a System Software Engineer (2021, 2022) at <a href="https://www.hpe.com/us/en/home.html" target="_blank">HPE</a>.
		</p>
			 

		<p>
              <p style="text-align:center">
                <a href="mailto:tianliu1327@gmail.com">Email</a> &nbsp/&nbsp
				<a href="https://scholar.google.com/citations?hl=en&user=qgmIiSsAAAAJ&view_op=list_works&sortby=pubdate" target="_blank"> Google Scholar </a> &nbsp/&nbsp
				<a href="data/CV_Tian Liu.pdf"  target="_blank"> CV </a> &nbsp/&nbsp
				<a href="https://www.linkedin.com/in/tian1327/" target="_blank"> LinkedIn </a> &nbsp/&nbsp
				<a href="https://github.com/tian1327" target="_blank"> Github </a>
              </p>
	  
            </td>
            <td style="padding:2.5%;width:20%;max-width:23%">
              <a href="images/tian_liu.png"><img style="width:120%;max-width:100%" alt="profile photo" src="images/tian_liu.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>



	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <p><heading>News</heading> </p>
		<p> 

	 <ul class="b">
	<li> Nov 7, 2024: our paper <a href="https://dl.acm.org/doi/pdf/10.1145/3671127.3698186" target="_blank"> ERIC</a> has won <a href="https://buildsys.acm.org/2024/" target="_blank">ACM BuildSys'24</a> 
		<b><font color="red">Best paper award !!!</font></b> </li> 
	<li> Oct 2024: 1 paper on adapting foundation model for video understanding was accepted to <a href="https://wacv2025.thecvf.com/" target="_blank">WACV'25</a>. </li> 
	<li> Sep 2024: 1 paper on building efficient computer vision system was accepted to <a href="https://buildsys.acm.org/2024/" target="_blank">ACM BuildSys'24</a> 
		as <b><font color="red">Best paper candidate!</font></b> </li> 
	<li> June 2024: Coordinated the <a href="https://vplow.github.io/vplow_4th.html" target="_blank">4th Open World Vision Workshop</a> at CVPR'24. </li>
	<li> June 2024: I will present our paper in CVPR'24, Seattle. </li>
	<li> June 2024: Our paper "The Neglected Tails in Vision-Language Models" was accepted to <b>ICML 2024 DMLR Oral</b>. </li>
	<li> Mar 2024: I was awarded TAMU CSE department travel grant. </li>
	<li> Mar 2024: I received TAMU CSE <b>Graduate Teaching Assistant Excellence Award</b> (1 each year). </li>
	<li> Mar 2024: I passed Ph.D. qualify exam with 99% percentile. </li>
	<li> Feb 2024: 1 paper on improving Vision Language Models for zero-shot recognition was accepted to <a href="https://cvpr.thecvf.com/" target="_blank">CVPR'24</a>. </li>



	</ul>	
        </td>
        </tbody></table>
	
	<p> 
	<p> 
		
		
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <p><heading>Research</heading> </p>
	<p> 

	My research focuses on <b>computer vision with Vision Language Models</b>, addressing a central question: 
	<i>"how to adapt pretrained foundation models to better serve specific downstream tasks, with none or limited labeled data?"</i>. 
	This question drives my efforts to identify and analyze the limitations of foundation models, examining their pretraining data 
	to understand the origins of these limitations. My prior work includes developing advanced prompting and retrieval-augmented 
	learning techniques for <b>zero-shot recognition</b>, as well as stage-wise augmented finetuning methods for <b>few-shot recognition</b>.
	I am also exploring the application of foundation models for <b>video understanding</b>, with specific interests in detecting unusual activities, 
	such as failure actions or behaviors indicative of autism in children.
	
	</p>
	
	<p>
	In addition, I have broad interest in <b>cyber-physical systems</b>, including developing efficient machine learning systems on resource-constrained
	edge devices. Applications include efficient vision system for precision residential irrigation and voice assistance system for emergency medical services. 
	</p>

	<p>

	Beyond these areas, my research extends to <b>machine learning for healthcare and geoscience</b>. This includes developing safe reinforcement learning 
	algorithms for personalized medicine; enhancing the fairness of cardiovascular disease (CVD) risk prediction models for underrepresented populations;
	advancing geoscientific methods for characterizing subsurface fracture distribution and integrating 4D seismic data for more accurate reservoir 
	model calibration.
	</p>

	<!-- My research interest includes <b>computer vision</b>, <b>cyber-physical systems</b>, and <b>machine learning for healthcare</b>. -->
	<!-- My current research focuses on analyzing the limitations of pretrained foundation models (e.g. Vision-Language Models)   -->
	<!-- and developing better algorithms to adapt foundation models to downstream tasks in zero-shot and few-shot setup. -->

	 <!-- <ul class="b"> 
	<li> <b>Machine Learning Systems for IoT</b>: addresses real-world challenges for advancing ML in mobile/IoT systems, such as distributed and imperfect IoT data, scalability, limited resources, and real-world system dynamics.  </li>
	<li><b>Cyber-physical Systems</b>: design and deploy real-world IoT systems for precision residential irrigation system and , e.g., developing multi-modal federated learning systems for <a href="https://cuhk-alzheimers-ai.github.io/">monitoring digital biomarkers of Alzheimerâ€™s Disease</a>. </li>
	<li><b>Machine Learning for Healthcare</b>: develop safe reinforcement learning algorithms and models for . </li>		 
	</ul>

	<b>Keywords of my recent research topics</b>: Vision-Language Models, zero/few-shot recognition, video understanding
	</td> -->
    </tbody></table>

		
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		
	<!-- <p><heading>Major Publications</heading></p> -->



	<tr">
	<td style="padding:0px;width:40%;vertical-align:middle">
	<div class="one" style="text-align:center;">
	<img src='images/ERIC.png' width="350">
	</div>
	</td>
	<td style="padding:10px;width:75%;vertical-align:middle">
	<p> <a href="https://dl.acm.org/doi/pdf/10.1145/3671127.3698186" target="_blank"> 
		ERIC: Estimating Rainfall with Commodity Doorbell Camera for Precision Residential Irrigation</a>
	</p>
	<u><b>Tian Liu</b></u>, Liuyi Jin, Radu Stoleru, Amran Haroon, Charles Swanson, Kexin Feng<br>
	<p> 
		[<b>BuildSys 2024</b>] &nbsp;
		<a href="https://buildsys.acm.org/2024/program/" target="_blank"><b><font color="red">Best paper award (1 out of 89 submissions)</font></b></a>
	</p> 
	<p>
		<a href="https://dl.acm.org/doi/pdf/10.1145/3671127.3698186" target="_blank"> paper</a> /
		<a href="https://arxiv.org/abs/2409.13104" target="_blank"> arxiv</a> /
		<a href="data/Tian-BuildSys'24-ERIC.pdf" target="_blank"> slides</a> /
		<a href="https://github.com/LENSS/ERIC-BuildSys2024.git" target="_blank"> code</a>
	</p>
	<p>We develop efficient vision system to estimate hyperlocal rainfall from doorbell camera for precision residential irrigation, 
		saving > 9,000 gallons of water per month.</p>
	</p>
	</td>			
	</tr>






	<ul class="b">

	  <tr">
	    <td style="padding:0px;width:40%;vertical-align:middle">
	    <div class="one" style="text-align:center;">
		<img src='images/swat_teaser.png' width="350" >
	    </div>
	    </td>
		<td style="padding:10px;width:75%;vertical-align:middle">
		<p> 
			<a href="https://arxiv.org/abs/2406.11148" target="_blank"> Few-Shot Recognition via Stage-Wise Augmented Finetuning</a>
		</p>
		<u><b>Tian Liu</b></u>, Huixin Zhang, Shubham Parashar, Shu Kong<br>		
		<!-- <em>CVPR</em>, 2024		 -->
		<p> 
			<a href="https://arxiv.org/abs/2406.11148" target="_blank"> arxiv</a> /
			<a href="https://tian1327.github.io/SWAT/" target="_blank"> project</a> /
			<a href="https://github.com/tian1327/SWAT" target="_blank"> code</a>
		</p> 
		<p>We explore retrieval-augmented learning for few-shot recognition, 
			and propose Stage-Wise Augmented fineTuning (SWAT) method to mitigate the imbalanced distribution and domain gap issues, 
			outperforming previous SOTA methods by >10% accuracy. </p>
		</td>			
		</tr>
			

		<tr">
	    <td style="padding:0px;width:40%;vertical-align:middle">
	    <div class="one" style="text-align:center;">
		<img src='images/real_teaser.jpg' width="350" >
	    </div>
	    </td>
		<td style="padding:10px;width:75%;vertical-align:middle">
		<p> <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Parashar_The_Neglected_Tails_in_Vision-Language_Models_CVPR_2024_paper.pdf" target="_blank"> 
			The Neglected Tails in Vision-Language Models</a>
		</p>
		Shubham Parashar*, Zhiqiu Lin*, <u><b>Tian Liu*</b></u> (*co-first authors), Xiangjue Dong,
		Yanan Li, Deva Ramanan, James Caverlee, Shu Kong<br>
		<p> 
			[<b>CVPR 2024, <a href="https://dmlr.ai/" target="_blank">ICML 2024 DMLR Oral</a></b>]	 &nbsp;
			<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Parashar_The_Neglected_Tails_in_Vision-Language_Models_CVPR_2024_paper.pdf" target="_blank"> paper</a> /
			<a href="https://openreview.net/pdf?id=ApWIco3gwD" target="_blank"> DMLR</a> /
			<a href="https://arxiv.org/abs/2401.12425" target="_blank"> arxiv</a> /			
			<a href="https://shubhamprshr27.github.io/neglected-tails-of-vlms/" target="_blank"> project</a> /
			<a href="https://github.com/shubhamprshr27/NeglectedTailsVLM" target="_blank"> code</a>
		</p> 
		<p>We expose the long-tailed concept distributions in VLMs' pretraining data 
			and reveal failues of SOTA multimodal systems (e.g. GPT-4V, DALL-E 3). 
			We propose retrieval-augmented learning, achieving SOTA zero-shot recognition performance. </p>
		</p>
		</td>			
		</tr>





		<tr">
	    <td style="padding:0px;width:40%;vertical-align:middle">
	    <div class="one" style="text-align:center;">
		<img src='images/emsassist_teaser.png' width="350" height="160">
	    </div>
	    </td>
		<td style="padding:10px;width:75%;vertical-align:middle">
		<p> <a href="https://dl.acm.org/doi/pdf/10.1145/3581791.3596853" target="_blank"> 
			EMSAssist: An End-to-End Mobile Voice Assistant at the Edge for
			Emergency Medical Services</a>
		</p>
		Liuyi Jin, <u><b>Tian Liu</b></u>, Amran Haroon, Radu Stoleru, Michael Middleton, Ziwei Zhu, Theodora Chaspari<br>
		<p> 
			[<b>MobiSys 2023</b>] &nbsp;
			<a href="https://dl.acm.org/doi/pdf/10.1145/3581791.3596853" target="_blank"> paper</a> /
			<a href="https://dl.acm.org/doi/pdf/10.1145/3581791.3597290" target="_blank">demo</a> /
			<a href="https://www.youtube.com/watch?v=bj7aQJKf4aE" target="_blank">video</a> /
			<a href="https://github.com/LENSS/EMSAssist" target="_blank"> code</a>
		</p> 
		<p>We build the first end-to-end mobile voice assistant system to assist Emergency Medical Technicians in selecting proper protocols for critical medical intervention. </p>
		</p>
		</td>			
		</tr>
		<br>
		<br>	


		<tr">
	    <td style="padding:0px;width:40%;vertical-align:middle">
	    <div class="one" style="text-align:center;">
		<img src='images/cops_teaser.png' width="350"height="150">
	    </div>
	    </td>
		<td style="padding:10px;width:75%;vertical-align:middle">
		<p> <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4583667" target="_blank"> 
			Safe Reinforcement Learning with Contextual Information: Theory and Applications</a>
		</p>
		Junyu Cao, Esmaeil Keyvanshokooh, <u><b>Tian Liu</b></u> <br>
		<p> 
			<!-- [<b>MobiSys 2023</b>] &nbsp; -->
			<a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4583667" target="_blank"> ssrn</a> /
			<a href="" target="_blank"> code</a>
		</p> 
		<p>We develop a safe reinforcement learning algorithm for personalized medical prescription considering patient's contextual information
			(e.g. age, gender, race etc.),
			achieveing sub-linear regret with zero safety violation.
		</p>
		</p>
		</td>			
		</tr>


		<tr">
	    <td style="padding:0px;width:40%;vertical-align:middle">
	    <div class="one" style="text-align:center;">
		<img src='images/vae_frac.png' width="350"height="150">
	    </div>
	    </td>
		<td style="padding:10px;width:75%;vertical-align:middle">
		<p> <a href="https://www.sciencedirect.com/science/article/pii/S0266352X2400082X" target="_blank"> 
			A Machine Learning-based Hybrid Model for Fracture Parameterization and
			Distribution Prediction in Unconventional Reservoirs</a>
		</p>
		<u><b>Tian Liu</b></u>, Ruxin Zhang <br>
		<p> 
			[<b>Computers and Geotechnics 2024</b>] &nbsp;
			<a href="https://www.sciencedirect.com/science/article/pii/S0266352X2400082X" target="_blank"> paper</a> 
			<!-- <a href="" target="_blank"> code</a> -->
		</p> 
		<p>We develop Variational Autoencoder (VAE) model for fracture parameterization 
			and distribution prediction using reservoir production data.
		</p>
		</p>
		</td>			
		</tr>




		<tr">
	    <td style="padding:0px;width:40%;vertical-align:middle">
	    <div class="one" style="text-align:center;">
		<img src='images/onset_time.png' width="350"height="150">
	    </div>
	    </td>
		<td style="padding:10px;width:75%;vertical-align:middle">
		<p> <a href="https://www.sciencedirect.com/science/article/pii/S0920410520300851" target="_blank"> 
			Integration of Time-lapse Seismic Data using the Onset Time Approach: the Impact of Seismic Survey Frequency</a>
		</p>
		<u><b>Tian Liu</b></u>, Hongquan Chen, Gill Hetz, Akhil Datta-Gupta <br>
		<p> 
			[<b>Journal of Petroleum Science and Engineering 2020</b>] &nbsp;			
		</p> 
		<p>
			<a href="https://engineering.tamu.edu/news/2018/02/petroleum-engineering-hosts-annual-student-paper-contest.html" target="_blank"><b><font color="red">1st Place of TAMU Student Paper Contest</font></b></a>,
			<!-- <a href="https://www.spe.org/en/students/contest/winners/#:~:text=Master%27s%20Division%0ATian%20Liu%2C%20Texas%20A%26M%20University" target="_blank"><b><font color="red">1st in Gulf Coast Region</font></b></a>, -->
			<a href="https://www.spe.org/en/students/contest/winners/#:~:text=Tian%20Liu%2C%20Texas%20A%26M%20University" target="_blank"><b><font color="red">3rd Place of International Championship</font></b></a>
		</p>
		<p>
			<a href="https://www.sciencedirect.com/science/article/pii/S0920410520300851" target="_blank"> JPSE journal paper</a> /
			<a href="https://onepetro.org/SPEATCE/proceedings-abstract/19ATCE/19ATCE/D011S008R001/217609" target="_blank"> ATCE  paper</a> 
			<!-- <a href="data/" target="_blank"> slides</a>  -->
			<!-- <a href=""> code</a> -->
		</p>
		<p>We develop onset-time approach for efficient 
			and robust integration of 4D seismic data for reservoir model calibration, achieveing 2x error reduction and 6x speedup 
			compared to traditional amplitude-matching methods. 
		</p>
		</p>
		</td>			
		</tr>



		
	<!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
               <p><heading>Other Publications</heading> </p>
		<p> 
	     <ul class="b">
		     
		<li> <a href="https://www.sciencedirect.com/science/article/pii/S0266352X2400082X" target="_blank"> A Machine Learning-based Hybrid Model for Fracture Parameterization and
			Distribution Prediction in Unconventional Reservoirs </a> 
		</li>
		<u><b>Tian Liu</b></u>, Ruxin Zhang<br>
		<i>Computers and Geotechnics, 2024.</i><br></p>
		 </td>
        </tbody></table>
		
	<p> <p> -->



	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
               <!-- <p><heading>Teaching Experience</heading> </p> -->
               <p><heading>Teaching Assistance</heading> </p>

		<p> 
	     <ul class="b">
	
		<!-- <p> <b> Mentering Experience </b> </p> -->
		<!-- <li>Huixin Zhang, Ph.D. student at TAMU </li> -->
		<!-- <li>Hasnat Md. Abdullah, Ph.D. student at TAMU </li> -->
		<!-- <li>Anwesha Basu, M.S. student at TAMU </li> -->
		<!-- <li>Yang Yang, undergraduate student at Georgia Tech </li> -->


		     
	<p> 
		
	  <!-- <p> <b> Teaching Assistant</b> </p> -->
	     <li> CSCE606: Software Engineering, 2023 Fall</li> </li>
	     <li> CSCE313: Introduction to Computer Systems, 2023 Summer</li> </li>
	     <li> CSCE110: Programming I, 2023 Summer</li> </li>
	     </ul>

            </td>
        </tbody></table>

	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
               <p><heading>Professional Services</heading> </p>
		<!-- <p>  -->
	     <ul class="b">
		  <!-- <p> <b> Organizing Committee Member </b> </p> -->
		  <!-- <p> <b> Organizing Conference </b> </p> -->

		      <li> Coordinator of <a href="https://vplow.github.io/vplow_4th.html" target="_blank">4th Open World Vision Workshop</a> at CVPR'24.</a> </li>
		     <!-- </p> -->
		    
		
              <!-- <p> <b> Invited Reviewer</b> </p> -->
	      <li> Reviewer for Pattern Recognition, WACV'25</li>
	      <li> Reviewer for Applied Thermal Engineering, Geoenergy Science and Enginerring, SPE Journal</li>
  
		</p>

	     </ul>

            </td>
        </tbody></table>


		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
               <p><heading>Selected Awards</heading> </p>
		<p> 
	     <ul class="b"> 
			<li> BuildSys, Best Paper Award, <em>2024</em> </li>
			<li> TAMU CSE Department Travel Grant, <em>2024</em> </li>
			<li> TAMU CSE Department <b>Graduate Teaching Assistant Excellence Award</b> (1 each year), <em>2024</em> </li>
			<li> 1st place of SPE Student Paper Contest in TAMU, 1st place of Gulf Coast Region, 3rd place of International Championship, <em>2018</em> </li>			
			<li> 2nd place of SPE Petrobowl Knowledge Contest in North American Region, <em>2017</em> </li>
			<li> 1st place of SPE Petrobowl Knowledge Contest in Asia-Pacific Region, <em>2015</em> </li>
			<li> Dean's Award (4 out of 296), China University of Petroleum Beijing, <em>2014</em> </li>
	      <li> National Scholarship (highest honor in China), Ministry of Education of China, <em>2012</em> </li>
	     </ul>

            </td>
        </tbody></table>

		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
			<p><heading>Miscellaneous</heading> </p>
	  <ul class="b">
		<!-- <li> .</a> </li> -->
		<li> I have two big (20 lbs :) orange Maine Coon brothers, named <a href="images/thor_loki.png" target="_blank">Thor and Loki</a>. </li>
	 </p>
	  </ul>
		 </td>
	 </tbody></table>



	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		<tr>
		  <td style="padding:0px">
			<br>
			<p style="text-align:right;float:right;font-size:small;align-items:center;">				
				<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=c3ccce&w=a&t=tt&d=dA0_VvsLwr-USfVcXqYjKU8s3yI3Xc5HNebwd6HIgjM&co=ffffff&cmo=fc6c6c&cmn=4953ff&ct=828080'></script>
				Template modified from <a href="https://jonbarron.info/" target="_blank">Jon Barron</a>
			</p> 
		  </td>
		</tr>
	  </tbody></table>

      </td>
    </tr>
  </table>
</body>

</html>
